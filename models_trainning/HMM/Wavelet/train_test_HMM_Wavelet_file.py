import numpy as np
import torchaudio
import joblib
import pywt
from hmmlearn import hmm
import os
import torch

def time_to_seconds(timestamp):
    h, m, s = map(int, timestamp.split(":"))
    return h * 3600 + m * 60 + s

def load_script(script_path):
    segments, speakers = [], []
    with open(script_path, "r", encoding="utf-8") as file:
        for line in file:
            start, end, speaker = line.strip().split()
            segments.append((time_to_seconds(start), time_to_seconds(end)))
            speakers.append(speaker)
    return segments, speakers

def extract_wavelet_features(audio_path, segments_speakers, wavelet='db4', level=1):
    """
    TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng báº±ng biáº¿n Ä‘á»•i wavelet thay vÃ¬ X-vector
    
    Parameters:
    - audio_path: ÄÆ°á»ng dáº«n Ä‘áº¿n file Ã¢m thanh
    - segments_speakers: Danh sÃ¡ch cÃ¡c cáº·p ((start, end), speaker)
    - wavelet: Loáº¡i wavelet sá»­ dá»¥ng (máº·c Ä‘á»‹nh: 'db4')
    - level: Sá»‘ cáº¥p Ä‘á»™ phÃ¢n tÃ­ch wavelet (máº·c Ä‘á»‹nh: 5)
    
    Returns:
    - Dictionary chá»©a Ä‘áº·c trÆ°ng wavelet cho má»—i ngÆ°á»i nÃ³i
    """
    waveform, sample_rate = torchaudio.load(audio_path)
    if waveform.shape[0] > 1:
        waveform = waveform.mean(dim=0)  # Chuyá»ƒn stereo thÃ nh mono
    
    waveform = waveform.numpy().squeeze()
    
    print(f"âš¡ Sample rate: {sample_rate}, Sá»‘ máº«u: {waveform.shape}")

    feature_dict = {}
    
    # HÃ m an toÃ n Ä‘á»ƒ tÃ­nh cÃ¡c thá»‘ng kÃª
    def safe_stat(func, arr, default=0.0):
        if len(arr) == 0:
            return default
        return func(arr)
    
    for (start, end), speaker in segments_speakers:
        start_sample = int(start * sample_rate)
        end_sample = int(end * sample_rate)
        print("start sample: ", start_sample)
        print("end sample: ", end_sample)
        segment_waveform = waveform[start_sample:end_sample]
        print("segment_waveform len():: ", len(segment_waveform))
        # Äáº£m báº£o Ä‘oáº¡n Ã¢m thanh Ä‘á»§ dÃ i cho phÃ¢n tÃ­ch wavelet
        if len(segment_waveform) < 2**level:
            print(f"âš ï¸ Äoáº¡n Ã¢m thanh quÃ¡ ngáº¯n cho ngÆ°á»i nÃ³i {speaker}, Ä‘ang bá» qua")
            continue
        
        if len(segment_waveform) == 0:
            print(f"âš ï¸ Cáº£nh bÃ¡o: Äoáº¡n {start}-{end} cá»§a {speaker} bá»‹ rá»—ng!")
            continue  # Bá» qua Ä‘oáº¡n nÃ y

        # Thá»±c hiá»‡n biáº¿n Ä‘á»•i wavelet Ä‘a phÃ¢n giáº£i
        coeffs = pywt.wavedec(segment_waveform, wavelet, level=min(level, pywt.dwt_max_level(len(segment_waveform), pywt.Wavelet(wavelet).dec_len)))
        
        # Táº¡o vector Ä‘áº·c trÆ°ng tá»« cÃ¡c há»‡ sá»‘ wavelet
        features = []
        for i, coeff in enumerate(coeffs):
            # TÃ­nh cÃ¡c Ä‘áº·c trÆ°ng thá»‘ng kÃª tá»« má»—i má»©c wavelet (vá»›i xá»­ lÃ½ máº£ng rá»—ng)
            features.extend([
                safe_stat(np.mean, coeff),        # GiÃ¡ trá»‹ trung bÃ¬nh
                safe_stat(np.std, coeff, 1.0),    # Äá»™ lá»‡ch chuáº©n
                safe_stat(np.max, coeff),         # GiÃ¡ trá»‹ lá»›n nháº¥t
                safe_stat(np.min, coeff),         # GiÃ¡ trá»‹ nhá» nháº¥t
                safe_stat(np.median, coeff),      # GiÃ¡ trá»‹ trung vá»‹
                safe_stat(lambda x: np.sum(x**2), coeff)  # NÄƒng lÆ°á»£ng
            ])
        
        # Chuyá»ƒn thÃ nh máº£ng numpy
        features = np.array(features)
        
        # ThÃªm vÃ o dictionary
        if speaker not in feature_dict:
            feature_dict[speaker] = []
        feature_dict[speaker].append(features)
    
    return feature_dict

def train_hmm_for_speaker(speaker, features):
    if not features:
        print(f"âš ï¸ KhÃ´ng cÃ³ Ä‘áº·c trÆ°ng Ä‘á»ƒ huáº¥n luyá»‡n cho ngÆ°á»i nÃ³i {speaker}")
        return
    
    features = np.vstack(features)  # Chuyá»ƒn danh sÃ¡ch thÃ nh máº£ng numpy
    
    # Chuáº©n hÃ³a Ä‘áº·c trÆ°ng (quan trá»ng cho wavelet)
    mean = np.mean(features, axis=0)
    std = np.std(features, axis=0)
    # TrÃ¡nh chia cho 0 hoáº·c NaN
    std[std < 1e-10] = 1.0
    features = (features - mean) / std
    
    n_components = min(3, len(features))
    model = hmm.GaussianHMM(n_components, covariance_type="diag", n_iter=100)
    model.fit(features)
    os.makedirs("models", exist_ok=True)
    joblib.dump(model, f"models/{speaker}_model.pkl")
    # LÆ°u thÃªm thÃ´ng sá»‘ chuáº©n hÃ³a Ä‘á»ƒ sá»­ dá»¥ng khi dá»± Ä‘oÃ¡n
    joblib.dump((mean, std), f"models/{speaker}_norm_params.pkl")
    print(f"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh HMM cho {speaker}")

def load_hmm_model(speaker):
    model_path = f"models/{speaker}_model.pkl"
    norm_params_path = f"models/{speaker}_norm_params.pkl"
    
    if not os.path.exists(model_path) or not os.path.exists(norm_params_path):
        print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y mÃ´ hÃ¬nh cho {speaker}")
        return None, None
    
    model = joblib.load(model_path)
    mean, std = joblib.load(norm_params_path)
    return model, (mean, std)

def predict_speaker(speaker, features):
    model, norm_params = load_hmm_model(speaker)
    if model is None or not features:
        return []
    
    features = np.vstack(features)
    mean, std = norm_params
    # TrÃ¡nh chia cho 0 hoáº·c NaN trong chuáº©n hÃ³a
    std[std < 1e-10] = 1.0
    features = (features - mean) / std
    
    return model.predict(features)

# ======= Cháº¡y thá»­ nghiá»‡m =======
audio_file = "train_voice/extraordinary_strategic/raw.WAV"
script_file = "train_voice/extraordinary_strategic/script.txt"

# Load script
segments, speakers = load_script(script_file)

# TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng wavelet
feature_dict = extract_wavelet_features(audio_file, zip(segments, speakers))

# Huáº¥n luyá»‡n mÃ´ hÃ¬nh HMM
for speaker, features in feature_dict.items():
    train_hmm_for_speaker(speaker, features)

# # Dá»± Ä‘oÃ¡n (náº¿u cáº§n)
# for speaker, features in feature_dict.items():
#     predictions = predict_speaker(speaker, features)
#     print(f"ğŸ” Dá»± Ä‘oÃ¡n cho {speaker}: {predictions}")