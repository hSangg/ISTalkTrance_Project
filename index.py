import json
import os

from rouge_score import rouge_scorer

# T·∫°o RougeScorer
scorer = rouge_scorer.RougeScorer(["rouge1", "rouge2", "rougeL"], use_stemmer=True)

base_path = "test_voice"
overall_results = {"rouge1": [], "rouge2": [], "rougeL": []}

# Duy·ªát t·∫•t c·∫£ c√°c th∆∞ m·ª•c con trong test_voice
for folder_name in os.listdir(base_path):
    folder_path = os.path.join(base_path, folder_name)
    true_file = os.path.join(folder_path, "true_summarization.json")
    test_file = os.path.join(folder_path, "test_summarization.json")

    # B·ªè qua n·∫øu kh√¥ng t√¨m th·∫•y file c·∫ßn thi·∫øt
    if not os.path.isfile(true_file) or not os.path.isfile(test_file):
        print(f"B·ªè qua {folder_name} v√¨ thi·∫øu file.")
        continue

    with open(true_file, "r", encoding="utf-8") as f:
        true_data = json.load(f)

    with open(test_file, "r", encoding="utf-8") as f:
        test_data = json.load(f)

    references = [item["transcription"] for item in true_data]
    predictions = [item["transcription"] for item in test_data]

    results = {"rouge1": [], "rouge2": [], "rougeL": []}
    for ref, pred in zip(references, predictions):
        scores = scorer.score(ref, pred)
        results["rouge1"].append(scores["rouge1"].fmeasure)
        results["rouge2"].append(scores["rouge2"].fmeasure)
        results["rougeL"].append(scores["rougeL"].fmeasure)

    # T√≠nh trung b√¨nh t·ª´ng ch·ªâ s·ªë ROUGE cho th∆∞ m·ª•c hi·ªán t·∫°i
    avg = {key: sum(values) / len(values) if values else 0 for key, values in results.items()}

    print(f"\nüìÅ K·∫øt qu·∫£ cho th∆∞ m·ª•c: {folder_name}")
    for k, v in avg.items():
        print(f"{k}: {v:.4f}")

    # Th√™m v√†o t·ªïng
    for key in overall_results:
        overall_results[key].extend(results[key])

# T√≠nh ƒëi·ªÉm trung b√¨nh to√†n b·ªô
print("\nüåü T·ªïng k·∫øt OVERALL:")
for key in overall_results:
    all_scores = overall_results[key]
    avg_score = sum(all_scores) / len(all_scores) if all_scores else 0
    print(f"{key}: {avg_score:.4f}")
